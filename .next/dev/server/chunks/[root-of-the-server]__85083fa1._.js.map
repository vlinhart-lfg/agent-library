{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 154, "column": 0}, "map": {"version":3,"sources":["file:///Users/v.linhart/Desktop/agent-library-2/agent-library/lib/apify.ts"],"sourcesContent":["import { ApifyClient } from 'apify-client';\n\n// Initialize Apify client\nconst client = new ApifyClient({\n  token: process.env.APIFY_API_TOKEN,\n});\n\nexport interface ScrapedScenarioData {\n  title: string;\n  description: string;\n  instructions?: string;\n  apps: string;\n  authorName?: string;\n  category?: string;\n  makeScenarioId: string;\n  iframeUrl: string;\n  buttonUrl: string;\n}\n\n/**\n * Scrapes Make.com scenario page using Apify\n * @param makeScenarioUrl - Full URL to Make.com shared scenario\n * @returns Scraped scenario data\n */\nexport async function scrapeScenario(\n  makeScenarioUrl: string\n): Promise<ScrapedScenarioData> {\n  try {\n    // Validate URL\n    if (!makeScenarioUrl.includes('make.com/public/shared-scenario')) {\n      throw new Error('Invalid Make.com scenario URL');\n    }\n\n    // Extract scenario ID from URL\n    // Format: https://eu2.make.com/public/shared-scenario/8MrnUpeVs8c/...\n    const urlParts = makeScenarioUrl.split('/');\n    const scenarioIdIndex = urlParts.indexOf('shared-scenario') + 1;\n    const makeScenarioId = urlParts[scenarioIdIndex];\n\n    if (!makeScenarioId) {\n      throw new Error('Could not extract scenario ID from URL');\n    }\n\n    // Use Apify Web Scraper actor\n    const actorId = process.env.APIFY_ACTOR_ID || 'apify/web-scraper';\n\n    // Run the actor with pageFunction as string\n    // NOTE: pageFunction runs in browser context, NOT with Puppeteer page object\n    const pageFunction = `async function pageFunction(context) {\n      const { request, log, waitFor, jQuery: $ } = context;\n\n      // Wait for page to load dynamic content\n      try {\n        await waitFor(5000); // Wait 5 seconds for JS to render\n      } catch (e) {\n        log.info('Wait timeout, continuing...');\n      }\n\n      // Extract title from meta tags or h1\n      let title = '';\n      try {\n        const ogTitle = $('meta[property=\"og:title\"]').attr('content');\n        if (ogTitle) {\n            title = ogTitle.replace(' - Make.com Automation Scenario', '').trim();\n        }\n        \n        if (!title) {\n            title = $('h1').first().text().trim();\n        }\n      } catch (e) {\n        log.info('Title extraction failed:', e.message);\n      }\n\n      // Extract description from meta tags or body\n      let description = '';\n      try {\n        const metaDesc = $('meta[name=\"description\"]').attr('content');\n        const ogDesc = $('meta[property=\"og:description\"]').attr('content');\n        \n        if (metaDesc) description = metaDesc;\n        else if (ogDesc) description = ogDesc;\n        \n        // Fallback to body text if meta tags are missing\n        if (!description) {\n             const bodyText = document.body.innerText || '';\n             const lines = bodyText.split('\\\\n').map(l => l.trim()).filter(l => l.length > 0);\n             if (lines.length > 1) {\n                for (let i = 1; i < Math.min(lines.length, 10); i++) {\n                    const line = lines[i];\n                    if (line.length > 30 && !line.startsWith('Use this') && !line.startsWith('\\ud83d\\udc47')) {\n                        description = line;\n                        break;\n                    }\n                }\n             }\n        }\n      } catch (e) {\n        log.info('Description extraction failed:', e.message);\n      }\n\n      // Extract instructions\n      let instructions = '';\n      try {\n        const bodyText = document.body.innerText || '';\n        // Case insensitive search for headers\n        const lowerBody = bodyText.toLowerCase();\n        const infoIndex = lowerBody.indexOf('additional information');\n        const howToIndex = lowerBody.indexOf('how to use this automation');\n\n        let startIndex = -1;\n        if (infoIndex > -1) startIndex = infoIndex;\n        else if (howToIndex > -1) startIndex = howToIndex;\n\n        if (startIndex > -1) {\n          const instructionsText = bodyText.substring(startIndex, startIndex + 1000);\n          instructions = instructionsText\n            .split('\\\\n')\n            .slice(0, 20)\n            .map(l => l.trim())\n            .filter(l => l.length > 0)\n            .join('\\\\n');\n        }\n      } catch (e) {\n         log.info('Instructions extraction failed:', e.message);\n      }\n\n      // Extract author name\n      let authorName = '';\n      try {\n          // Look for the author structure: div.dmo-flex.dmo-items-center > p.title\n          const authorTitle = $('.dmo-flex.dmo-items-center p.title').first();\n          if (authorTitle.length > 0) {\n              authorName = authorTitle.text().trim();\n          }\n      } catch(e) {\n          log.info('Author detection failed', e.message);\n      }\n\n      // Extract apps from img alt attributes, excluding author\n      let apps = '';\n      try {\n        const appNames = new Set();\n        const excludeNames = ['Make Logo', 'Company Logo', 'Powered by', 'Onetrust'];\n        \n        $('img').each(function() {\n          const alt = $(this).attr('alt');\n\n          if (alt && alt.trim().length > 0 && alt.length < 50) {\n            // Exclude common non-app images\n            const isExcluded = excludeNames.some(excluded => alt.includes(excluded));\n            // Exclude author name\n            const isAuthor = authorName && alt.includes(authorName);\n            \n            if (!isExcluded && !isAuthor) {\n              appNames.add(alt.trim());\n            }\n          }\n        });\n\n        apps = Array.from(appNames).join(', ');\n      } catch (e) {\n        log.info('Apps extraction failed:', e.message);\n      }\n\n      // Extract interactive iframe URL\n      let interactiveIframeUrl = '';\n      try {\n        const iframe = $('iframe.inspector-frame').first();\n        if (iframe.length > 0) {\n          interactiveIframeUrl = iframe.attr('src') || '';\n          log.info('Found iframe URL: ' + interactiveIframeUrl);\n        }\n      } catch (e) {\n        log.info('Iframe extraction failed:', e.message);\n      }\n\n      // Fallback title from slug\n      if (!title || title.trim().length === 0) {\n        const urlParts = request.url.split('/');\n        const slug = urlParts[urlParts.length - 1];\n        title = slug\n          .split('-')\n          .map(word => word.charAt(0).toUpperCase() + word.slice(1))\n          .join(' ');\n      }\n\n      return {\n        url: request.url,\n        title: title.trim(),\n        description: description.trim(),\n        instructions: instructions.trim(),\n        apps: apps.trim(),\n        interactiveIframeUrl: interactiveIframeUrl.trim(),\n        authorName: authorName ? authorName.trim() : '',\n      };\n    }`;\n\n    const run = await client.actor(actorId).call({\n      startUrls: [{ url: makeScenarioUrl }],\n      pageFunction: pageFunction,\n      proxyConfiguration: {\n        useApifyProxy: true,\n      },\n      maxRequestRetries: 2,\n      maxConcurrency: 1,\n    });\n\n    // Wait for the actor to finish\n    await client.run(run.id).waitForFinish();\n\n    // Fetch results\n    const { items } = await client.dataset(run.defaultDatasetId).listItems();\n\n    if (!items || items.length === 0) {\n      throw new Error('No data extracted from page');\n    }\n\n    const scraped = items[0] as any;\n\n    // Use extracted iframe URL or generate as fallback\n    let iframeUrl = scraped.interactiveIframeUrl || '';\n\n    // Fallback: Generate iframe URL if not extracted\n    // Pattern: https://eu2.make.com/public/shared-scenario/standalone-inspector-previewer/[SCENARIO_ID]\n    if (!iframeUrl) {\n      iframeUrl = `https://eu2.make.com/public/shared-scenario/standalone-inspector-previewer/${makeScenarioId}`;\n    }\n\n    const buttonUrl = makeScenarioUrl;\n\n    // Return structured data\n    return {\n      title: scraped.title || 'Untitled Scenario',\n      description: scraped.description || '',\n      instructions: scraped.instructions || '',\n      apps: scraped.apps || '',\n      authorName: scraped.authorName || '',\n      category: undefined, // Will be determined by AI\n      makeScenarioId,\n      iframeUrl,\n      buttonUrl,\n    };\n  } catch (error: any) {\n    console.error('Apify scraping error:', error);\n    throw new Error(`Failed to scrape scenario: ${error.message}`);\n  }\n}\n\n/**\n * Check Apify account usage and limits\n */\nexport async function checkApifyUsage() {\n  try {\n    const user = await client.user().get();\n    return {\n      username: user?.username,\n      plan: user?.proxy?.plan,\n      // Add more usage details as needed\n    };\n  } catch (error) {\n    console.error('Failed to check Apify usage:', error);\n    return null;\n  }\n}\n"],"names":[],"mappings":";;;;;;AAAA;;AAEA,0BAA0B;AAC1B,MAAM,SAAS,IAAI,kKAAW,CAAC;IAC7B,OAAO,QAAQ,GAAG,CAAC,eAAe;AACpC;AAmBO,eAAe,eACpB,eAAuB;IAEvB,IAAI;QACF,eAAe;QACf,IAAI,CAAC,gBAAgB,QAAQ,CAAC,oCAAoC;YAChE,MAAM,IAAI,MAAM;QAClB;QAEA,+BAA+B;QAC/B,sEAAsE;QACtE,MAAM,WAAW,gBAAgB,KAAK,CAAC;QACvC,MAAM,kBAAkB,SAAS,OAAO,CAAC,qBAAqB;QAC9D,MAAM,iBAAiB,QAAQ,CAAC,gBAAgB;QAEhD,IAAI,CAAC,gBAAgB;YACnB,MAAM,IAAI,MAAM;QAClB;QAEA,8BAA8B;QAC9B,MAAM,UAAU,QAAQ,GAAG,CAAC,cAAc,IAAI;QAE9C,4CAA4C;QAC5C,6EAA6E;QAC7E,MAAM,eAAe,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;KAmJrB,CAAC;QAEF,MAAM,MAAM,MAAM,OAAO,KAAK,CAAC,SAAS,IAAI,CAAC;YAC3C,WAAW;gBAAC;oBAAE,KAAK;gBAAgB;aAAE;YACrC,cAAc;YACd,oBAAoB;gBAClB,eAAe;YACjB;YACA,mBAAmB;YACnB,gBAAgB;QAClB;QAEA,+BAA+B;QAC/B,MAAM,OAAO,GAAG,CAAC,IAAI,EAAE,EAAE,aAAa;QAEtC,gBAAgB;QAChB,MAAM,EAAE,KAAK,EAAE,GAAG,MAAM,OAAO,OAAO,CAAC,IAAI,gBAAgB,EAAE,SAAS;QAEtE,IAAI,CAAC,SAAS,MAAM,MAAM,KAAK,GAAG;YAChC,MAAM,IAAI,MAAM;QAClB;QAEA,MAAM,UAAU,KAAK,CAAC,EAAE;QAExB,mDAAmD;QACnD,IAAI,YAAY,QAAQ,oBAAoB,IAAI;QAEhD,iDAAiD;QACjD,oGAAoG;QACpG,IAAI,CAAC,WAAW;YACd,YAAY,CAAC,2EAA2E,EAAE,gBAAgB;QAC5G;QAEA,MAAM,YAAY;QAElB,yBAAyB;QACzB,OAAO;YACL,OAAO,QAAQ,KAAK,IAAI;YACxB,aAAa,QAAQ,WAAW,IAAI;YACpC,cAAc,QAAQ,YAAY,IAAI;YACtC,MAAM,QAAQ,IAAI,IAAI;YACtB,YAAY,QAAQ,UAAU,IAAI;YAClC,UAAU;YACV;YACA;YACA;QACF;IACF,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,yBAAyB;QACvC,MAAM,IAAI,MAAM,CAAC,2BAA2B,EAAE,MAAM,OAAO,EAAE;IAC/D;AACF;AAKO,eAAe;IACpB,IAAI;QACF,MAAM,OAAO,MAAM,OAAO,IAAI,GAAG,GAAG;QACpC,OAAO;YACL,UAAU,MAAM;YAChB,MAAM,MAAM,OAAO;QAErB;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,gCAAgC;QAC9C,OAAO;IACT;AACF"}},
    {"offset": {"line": 394, "column": 0}, "map": {"version":3,"sources":["file:///Users/v.linhart/Desktop/agent-library-2/agent-library/app/api/scrape/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server';\nimport { z } from 'zod';\nimport { scrapeScenario } from '@/lib/apify';\n\n// Rate limiting map (in-memory)\nconst rateLimit = new Map<string, { count: number; timestamp: number }>();\nconst RATE_LIMIT_WINDOW = 3600000; // 1 hour\nconst MAX_SCRAPES_PER_HOUR = parseInt(process.env.RATE_LIMIT_SCRAPES_PER_HOUR || '5');\n\nconst scrapeSchema = z.object({\n  makeScenarioUrl: z.string().url(),\n  enhance: z.boolean().optional(),\n});\n\nexport async function POST(request: Request) {\n  try {\n    // 1. Rate Limiting\n    const ip = request.headers.get('x-forwarded-for') || 'unknown';\n    const now = Date.now();\n    const userLimit = rateLimit.get(ip) || { count: 0, timestamp: now };\n\n    if (now - userLimit.timestamp > RATE_LIMIT_WINDOW) {\n      userLimit.count = 0;\n      userLimit.timestamp = now;\n    }\n\n    if (userLimit.count >= MAX_SCRAPES_PER_HOUR) {\n      return NextResponse.json(\n        { error: 'Rate limit exceeded. Please try again later.' },\n        { status: 429 }\n      );\n    }\n\n    userLimit.count++;\n    rateLimit.set(ip, userLimit);\n\n    // 2. Input Validation\n    const body = await request.json();\n    const validation = scrapeSchema.safeParse(body);\n\n    if (!validation.success) {\n      return NextResponse.json(\n        { error: 'Invalid URL provided' },\n        { status: 400 }\n      );\n    }\n\n    const { makeScenarioUrl } = validation.data;\n\n    // 3. Check Apify Configuration\n    if (!process.env.APIFY_API_TOKEN) {\n      console.error('APIFY_API_TOKEN is missing');\n      return NextResponse.json(\n        { error: 'Server configuration error' },\n        { status: 500 }\n      );\n    }\n\n    // 4. Perform Scraping\n    try {\n      const data = await scrapeScenario(makeScenarioUrl);\n      return NextResponse.json({ success: true, data });\n    } catch (error: any) {\n      console.error('Scraping failed:', error);\n      return NextResponse.json(\n        { error: error.message || 'Failed to scrape scenario' },\n        { status: 500 }\n      );\n    }\n\n  } catch (error) {\n    console.error('API Error:', error);\n    return NextResponse.json(\n      { error: 'Internal server error' },\n      { status: 500 }\n    );\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAEA,gCAAgC;AAChC,MAAM,YAAY,IAAI;AACtB,MAAM,oBAAoB,SAAS,SAAS;AAC5C,MAAM,uBAAuB,SAAS,QAAQ,GAAG,CAAC,2BAA2B,IAAI;AAEjF,MAAM,eAAe,yKAAC,CAAC,MAAM,CAAC;IAC5B,iBAAiB,yKAAC,CAAC,MAAM,GAAG,GAAG;IAC/B,SAAS,yKAAC,CAAC,OAAO,GAAG,QAAQ;AAC/B;AAEO,eAAe,KAAK,OAAgB;IACzC,IAAI;QACF,mBAAmB;QACnB,MAAM,KAAK,QAAQ,OAAO,CAAC,GAAG,CAAC,sBAAsB;QACrD,MAAM,MAAM,KAAK,GAAG;QACpB,MAAM,YAAY,UAAU,GAAG,CAAC,OAAO;YAAE,OAAO;YAAG,WAAW;QAAI;QAElE,IAAI,MAAM,UAAU,SAAS,GAAG,mBAAmB;YACjD,UAAU,KAAK,GAAG;YAClB,UAAU,SAAS,GAAG;QACxB;QAEA,IAAI,UAAU,KAAK,IAAI,sBAAsB;YAC3C,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAA+C,GACxD;gBAAE,QAAQ;YAAI;QAElB;QAEA,UAAU,KAAK;QACf,UAAU,GAAG,CAAC,IAAI;QAElB,sBAAsB;QACtB,MAAM,OAAO,MAAM,QAAQ,IAAI;QAC/B,MAAM,aAAa,aAAa,SAAS,CAAC;QAE1C,IAAI,CAAC,WAAW,OAAO,EAAE;YACvB,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAAuB,GAChC;gBAAE,QAAQ;YAAI;QAElB;QAEA,MAAM,EAAE,eAAe,EAAE,GAAG,WAAW,IAAI;QAE3C,+BAA+B;QAC/B,IAAI,CAAC,QAAQ,GAAG,CAAC,eAAe,EAAE;YAChC,QAAQ,KAAK,CAAC;YACd,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAA6B,GACtC;gBAAE,QAAQ;YAAI;QAElB;QAEA,sBAAsB;QACtB,IAAI;YACF,MAAM,OAAO,MAAM,IAAA,gIAAc,EAAC;YAClC,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,SAAS;gBAAM;YAAK;QACjD,EAAE,OAAO,OAAY;YACnB,QAAQ,KAAK,CAAC,oBAAoB;YAClC,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,OAAO,MAAM,OAAO,IAAI;YAA4B,GACtD;gBAAE,QAAQ;YAAI;QAElB;IAEF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,cAAc;QAC5B,OAAO,gJAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAAwB,GACjC;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}